Side project work log: total about 51-52hours total hours on each item:Design the work flowHours: 1read in yelp review and business info in jsonHours: 3Chanlleges: json has nested format make it hard to read in files interveted index add hours: 3challenges: while adding the term to interted index, we are pre-calculating sentiment typeprocess yelp data:Hours: 5challenges: the raw data has mixed business and their reviews, but I only need restaurant data and business info, so I used python to filter and pre-process business data from the category and then filter out the corresponding reviewssentiment analysis:hours: 6challenges: research on sentiment analysis and tried but its too slowredesign to boost performance:hours: 3redesign the work flow and made changes:hours: 5Challenges: the sentiment analysis script is slow to process all sentences since I was pre-calculating them, so I re-design it in a way i can compute sentiment analysis until I know the term instead of computing it upfrontProcess data againHours: 3challenges: noticed the data doesnt contains resturants in CA, so I picked portland and also filter out the data 10 years ago since they are not relatable any moreintegrate html with code:Hours: 3 jupyer notebook:Hours: 6Spotcheck on Sentiment analysis:Hour: 3Debugging:Hour: 4design html logo and font:Hour: 2clean code + refactoringHours: 4  ——total  51~52 hours